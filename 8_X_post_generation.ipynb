{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e76b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from typing import TypedDict,Literal,Annotated\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from google.generativeai as genai\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97789d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator_llm before using it\n",
    "generator_llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "evaluator_llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "optimizer_llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TweetEvaluation(BaseModel): \n",
    "    evaluation: Literal [\"approved\", \"needs_improvement\"] = Field (..., description=\"Final evaluation\")\n",
    "    feedback: str = Field(..., description-\"feedback for the tweet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92128f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_evaluator_llm = evaluator_llm.with_structured_output(TweetEvaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9c456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#state\n",
    "class TweetState(TypedDict)\n",
    "\n",
    "  topic : str\n",
    "  tweet : str\n",
    "  evaluation :Literal[\"approved\", \"need_improvement\"]\n",
    "  feedback:str\n",
    "  iteration : int\n",
    "  max_iteration : int\n",
    "  \n",
    "  tweet_history: Annotated[list[str],operator.add]\n",
    "  feedback_history: Annotated[list[str],operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2820002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tweet(state: TweetState):\n",
    "    \n",
    "    #prompt\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a funnay and clever twitter/X influencer.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "    Write a short, orginal, and hilarious tweet on the topic:\"{state['topic']}\".\n",
    "    \n",
    "    Rules:\n",
    "    -Do no use question_answer fromat.\n",
    "    -Max 280 characters.\n",
    "    -Use observational humor, irony, sarcasm, or cultural references.\n",
    "    -think in meme logic, punchlines, or relatable task.\n",
    "    -use simple, day to day english\n",
    "    -This is version'{state['iteration'] + 1}.\n",
    "    \"\"\")\n",
    "    ]\n",
    "    \n",
    "    #send generator_llm\n",
    "    response = generator_llm.invoke(messages).Content\n",
    "    \n",
    "    # Return response\n",
    "    \n",
    "    return {\"tweet\" : response, 'tweet_history':[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba82518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tweet(state:TweetState):\n",
    "    \n",
    "    \n",
    "    #prompt\n",
    "    messages = [\n",
    "        SystemMessage(content= \"You are a ruthless, no-laugh-given Twitter critic. You evaluate tweets based on humor, originally, virality, and tweet format.\"),\n",
    "Eualuate the following tweet:\n",
    "Tweet : \"{state[\"tweet\"]}\"\n",
    "\n",
    "Use the criteria below to evaluate the tweet:\n",
    "1. Originality - Is this fresh , or have  you seen it a hundred times before ?\n",
    "2. Humor - Did it genuinely make you smile, laugh, or chunkle?\n",
    "3. Punchiness - Is it short, sharp,and scroll-stopping?\n",
    "4. Virality Potential- would people retweet or share it ?\n",
    "5. Format- Is it a well-formed tweet (not a setup-punchline joke, not a Q&A joke, and  under 20 characters)?\n",
    "\n",
    "Auto-reject if :\n",
    "-It's written in question-answer format (e.g., \"Why did...\" or \"what happens when...\")\n",
    "-It exceeds 280 characters\n",
    "-It reads like a traditional setup_punchline joke\n",
    "-Dont end with generic, throwaway,or deflating lines that weaken the humar (e.g., \"Masterpieces of the auntie-uncle\n",
    "universe\" or vague summaries)\n",
    "\n",
    "##Responed only in structured  format:\n",
    "\n",
    "- evaluation : \"approved\"  or \"need_improvement\n",
    "- feedback: One paragraph explaining the strengths  and weaknesses\n",
    "\"\"\")\n",
    "]\n",
    "   \n",
    "   \n",
    "    response =  structured_evaluator_llm.invoke(messages) \n",
    "    \n",
    "    return {'evaluation':response.evaluation, 'feedback' : response.feedback, 'feedback_history'[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a3302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_tweet(state: TweetState):\n",
    "    \n",
    "    #prompt\n",
    "    messages = [\n",
    "        SystemMessage(conent=\"You punch up tweets for virality and humor based on given feedback.\"),\n",
    "        HumanMessage(content= f\"\"\"\n",
    "    Improve the tweet based on this feedback:\n",
    "    \"{state['feedback']}\"\n",
    "    \n",
    "    Topic: \"{state['topic']}\n",
    "    Orginal Tweet:\n",
    "    {state['tweet']}\n",
    "    \n",
    "    Re-write it as a short, viral-worthy tweet.Avoid Q&A style and stay under 280 characters.\n",
    "    \"\"\")\n",
    "    ]\n",
    "    \n",
    "    response= optimizer_llm.invoke(messages).content\n",
    "    iteration = state['iteration'] + 1\n",
    "    \n",
    "    return{'tweet': response, 'iteration': iteration, 'tweet_history': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c6e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roote_evaluation(state: TweetState):\n",
    "    \n",
    "    if state['evaluation'] == 'approved' or state['iteration']>= state['max_iteration']:\n",
    "        return 'apporved'\n",
    "    else:\n",
    "        return 'needs_improvement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d23a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(TweetState)\n",
    "\n",
    "graph.add_node('generate' , generate_tweet)\n",
    "graph.add_node('evaluate' , evaluate_tweet)\n",
    "graph.add_node('optimize' , optimize_tweet)\n",
    "\n",
    "graph.add_edge(START, 'generate')\n",
    "graph.add_edge('generate' , 'evaluate')\n",
    "\n",
    "#conditional edge\n",
    "graph.add_conditional_edge('evaluate', route_evaluation, ('approved':END, 'needs_improvement':'optimize'))\n",
    "graph.add_edge('optimize' , 'evaluate')\n",
    "\n",
    "workflow = graph.compile()\n",
    "\n",
    "workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ebebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"topic\" :\"Pakistan Railways\",\n",
    "     \"iteration\":1,\n",
    "     \"max_iteration\": 5\n",
    "}\n",
    "\n",
    "result = workflow.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c382e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3470720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in result['tweet_history']:\n",
    "    print(tweet)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
